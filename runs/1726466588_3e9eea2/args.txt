run.py train_policy_with_preferences Hopper-v4 --synthetic_prefs --ent_coef 0.02 --million_timesteps 0.15
Namespace(batchnorm=False, debug=False, dropout=0.0, ent_coef=0.02, env='Hopper-v4', load_policy_ckpt_dir=None, load_prefs_dir=None, load_reward_predictor_ckpt_dir=None, log_dir=None, log_interval=100, lr=0.0007, lr_zero_million_timesteps=None, max_prefs=3000, max_segs=1000, million_timesteps=0.15, mode='train_policy_with_preferences', n_envs=1, n_initial_epochs=200, n_initial_prefs=500, policy_ckpt_interval=100, render_episodes=False, reward_predictor_ckpt_interval=1, reward_predictor_learning_rate=0.0002, run_name='1726466588', seed=0, synthetic_prefs=True, test_mode=False)